import { Settings, SentenceSplitter } from 'llamaindex';
import { OpenAI, OpenAIEmbedding } from '@llamaindex/openai';
import { VectorStoreService } from './services/vectorStore';
import { QueryService } from './services/queryService';
import { AgentService } from './services/agentService';
import { CURRENT_DATASET, DATASET_CONFIGS, OPENAI_CONFIG, EMBEDDING_CONFIG, CHUNKING_CONFIG } from './config';

// åˆå§‹åŒ–LlamaIndexè®¾ç½®
Settings.llm = new OpenAI({
  model: OPENAI_CONFIG.model,
  apiKey: OPENAI_CONFIG.apiKey,
  temperature: OPENAI_CONFIG.temperature,
  baseURL: OPENAI_CONFIG.baseUrl,
});

Settings.embedModel = new OpenAIEmbedding({
  model: EMBEDDING_CONFIG.model,
  apiKey: EMBEDDING_CONFIG.apiKey,
  baseURL: EMBEDDING_CONFIG.baseUrl,
});

Settings.nodeParser = new SentenceSplitter({
  chunkSize: CHUNKING_CONFIG.chunkSize,
  chunkOverlap: CHUNKING_CONFIG.chunkOverlap,
  separator: CHUNKING_CONFIG.separator,
  paragraphSeparator: CHUNKING_CONFIG.paragraphSeparator,
});

// åˆ›å»ºæœåŠ¡å®ä¾‹
export const vectorStoreService = new VectorStoreService();
export const queryService = new QueryService(vectorStoreService);
export const agentService = new AgentService(vectorStoreService);

// åº”ç”¨ç¨‹åºç±»
export class RAGApplication {
  constructor(
    private vectorStoreService: VectorStoreService,
    private queryService: QueryService,
    private agentService: AgentService
  ) {}

  /**
   * åˆå§‹åŒ–åº”ç”¨ç¨‹åº
   */
  async initialize() {
    console.log('ğŸš€ åˆå§‹åŒ–RAGåº”ç”¨ç¨‹åº...');
    console.log(`ğŸ¯ å½“å‰æ•°æ®é›†: ${DATASET_CONFIGS[CURRENT_DATASET].description}`);

    // é¢„çƒ­ç´¢å¼•
    await this.vectorStoreService.getOrCreateIndex(CURRENT_DATASET);
    console.log('âœ… åº”ç”¨ç¨‹åºåˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * è·å–åº”ç”¨ç¨‹åºçŠ¶æ€
   */
  async getStatus() {
    const health = await this.vectorStoreService.checkHealth(CURRENT_DATASET);
    const stats = await this.vectorStoreService.getDatasetStats(CURRENT_DATASET);

    return {
      status: 'running',
      currentDataset: CURRENT_DATASET,
      health,
      stats,
      availableDatasets: Object.keys(DATASET_CONFIGS),
    };
  }

  /**
   * æ‰§è¡ŒæŸ¥è¯¢
   */
  async query(
    query: string,
    dataset = CURRENT_DATASET,
    options: {
      similarityTopK?: number;
      includeSourceNodes?: boolean;
    } = {
      similarityTopK: 5,
      includeSourceNodes: true,
    }
  ) {
    return await this.queryService.query(query, dataset, options);
  }

  /**
   * æ‰§è¡Œæ£€ç´¢
   */
  async retrieve(
    query: string,
    dataset = CURRENT_DATASET,
    options?: {
      similarityTopK?: number;
    }
  ) {
    return await this.queryService.retrieve(query, dataset, options);
  }

  /**
   * AgentæŸ¥è¯¢
   */
  async agentQuery(query: string, dataset = CURRENT_DATASET) {
    return await this.agentService.runQuery(query, dataset);
  }

  /**
   * Agentæµå¼æŸ¥è¯¢
   */
  agentQueryStream(query: string, dataset = CURRENT_DATASET) {
    return this.agentService.runQueryStream(query, dataset);
  }

  /**
   * è·¨æ•°æ®é›†æŸ¥è¯¢
   */
  async crossDatasetQuery(query: string, datasets?: Array<keyof typeof DATASET_CONFIGS>) {
    return await this.vectorStoreService.queryMultipleDatasets(
      query,
      datasets || ['price_index_statistics', 'machine_learning']
    );
  }

  /**
   * ç®¡ç†åŠŸèƒ½
   */
  async rebuildIndex(dataset = CURRENT_DATASET) {
    return await this.vectorStoreService.createNewIndex(dataset);
  }

  async deleteCollection(dataset = CURRENT_DATASET) {
    const config = DATASET_CONFIGS[dataset];
    return await this.vectorStoreService.deleteCollection(config.collectionName);
  }
}

export const app = new RAGApplication(vectorStoreService, queryService, agentService);
